<!-- SIMPLE FIX for initAudio function - Replace lines 223-299 -->
<!-- This follows the approach from test-mobile-mic.html which works -->

async function initAudio() {
    try {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') return;
        
        console.log('Requesting microphone...');
        status.textContent = 'Getting microphone...';
        
        // Simple audio request - PROVEN TO WORK!
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log('Got media stream');
        status.textContent = 'Microphone ready';
        
        // Create MediaRecorder FIRST with no format (like test page)
        mediaRecorder = new MediaRecorder(stream);
        console.log('MediaRecorder created with default format');
        
        mediaRecorder.ondataavailable = event => {
            console.log('Data available:', event.data.size);
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };
        
        mediaRecorder.onstop = async () => {
            console.log('MediaRecorder stopped, chunks:', audioChunks.length);
            if (audioChunks.length > 0) {
                const audioBlob = new Blob(audioChunks);
                console.log('Created blob, size:', audioBlob.size);
                audioChunks = [];
                await processAudio(audioBlob);
            } else {
                console.log('No audio chunks recorded');
                resetButton();
            }
        };
        
        mediaRecorder.onerror = (event) => {
            console.error('MediaRecorder error:', event.error);
            resetButton();
        };
        
        // NOW setup audio context for analysis (after MediaRecorder is ready)
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            console.log('Audio context created');
            
            // Resume if needed (iOS)
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }
        }
        
        // Create analyser AFTER MediaRecorder
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        
        // Use a CLONE of the stream for analysis to avoid interference
        const analysisStream = stream.clone();
        microphone = audioContext.createMediaStreamSource(analysisStream);
        microphone.connect(analyser);
        console.log('Audio analysis setup with cloned stream');
        
        // Start monitoring
        monitorAudioLevels();
        
    } catch (err) {
        console.error('Microphone access denied:', err);
        status.textContent = 'Microphone access required';
        micButton.disabled = true;
    }
}

<!-- ALTERNATIVE: If cloning still doesn't work, disable silence detection temporarily -->
<!-- In monitorAudioLevels function, replace the average calculation with: -->

function monitorAudioLevels() {
    if (!analyser) return;
    
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    const SILENCE_THRESHOLD = 30;
    const SILENCE_DURATION = 3500; // 3.5 seconds
    const INTERRUPT_THRESHOLD = 40;
    let silenceDuration = 0;
    
    function checkAudioLevel() {
        if (!isListening && !currentAudio) {
            requestAnimationFrame(checkAudioLevel);
            return;
        }
        
        analyser.getByteFrequencyData(dataArray);
        
        // Calculate average - but also check if we're getting any data
        const sum = dataArray.reduce((a, b) => a + b, 0);
        const average = sum / dataArray.length;
        
        // Debug log every second
        if (Date.now() % 1000 < 16) {
            console.log('Audio level - sum:', sum, 'average:', average.toFixed(2));
        }
        
        // If analyser is broken (sum is 0), use a fallback
        if (sum === 0 && mediaRecorder && mediaRecorder.state === 'recording') {
            // Don't auto-stop if analyser is broken
            console.log('Analyser returning 0 - skipping auto-stop');
            silenceDuration = 0;
            silenceProgress.style.width = '0%';
        } else {
            // Normal silence detection
            if (average < SILENCE_THRESHOLD) {
                silenceDuration += 16;
                const progress = Math.min(100, (silenceDuration / SILENCE_DURATION) * 100);
                silenceProgress.style.width = progress + '%';
                
                if (silenceDuration >= SILENCE_DURATION) {
                    console.log('Silence detected, stopping...');
                    stopListening();
                }
            } else {
                silenceDuration = 0;
                silenceProgress.style.width = '0%';
            }
        }
        
        // Update visualizer
        if (isListening && mediaRecorder.state === 'recording') {
            const bars = visualizer.querySelectorAll('.audio-bar');
            bars.forEach((bar, i) => {
                const height = Math.min(40, dataArray[i * 50] / 3);
                bar.style.height = height + 'px';
            });
        }
        
        requestAnimationFrame(checkAudioLevel);
    }
    
    checkAudioLevel();
}